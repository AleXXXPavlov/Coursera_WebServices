ЧАСТЬ 1

В этом задании вам необходимо реализовать парсер для сбора статистики со страниц Википедии. Чтобы упростить вашу задачу, необходимые страницы уже скачаны и 
сохранены на файловой системе в директории wiki/ (Например, страница https://en.wikipedia.org/wiki/Stone_Age сохранена файле wiki/Stone_Age). Парсер реализован в 
виде функции parse, которая принимает на вход один параметр: path_to_file — путь до файла, содержащий html код страницы википедии. Гарантируется, что такой путь 
существует. Ваша задача — прочитать файл, пройтись Beautiful Soup по статье, найти её тело (это <div id="bodyContent">) и внутри него подсчитать: 
  - Количество картинок (img) с шириной (width) не меньше 200. Например: <img width="200">, но не <img> и не <img width="199">
  
  - Количество заголовков (h1, h2, h3, h4, h5, h6), первая буква текста внутри которых соответствует заглавной букве E, T или C. Например: <h1>End</h1> или 
  <h5><span>Contents</span></h5>, но не <h1>About</h1> и не <h2>end</h2> и не <h3><span>1</span><span>End</span></h3>
  
  - Длину максимальной последовательности ссылок, между которыми нет других тегов, открывающихся или закрывающихся. Например: <p><span><a></a></span>, <a></a>, 
  <a></a></p> - тут 2 ссылки подряд, т.к. закрывающийся span прерывает последовательность. <p><a><span></span></a>, <a></a>, <a></a></p> - а тут 3 ссылки подряд, 
  т.к. span находится внутри ссылки, а не между ссылками.
  
  - Количество списков (ul, ol), не вложенных в другие списки. Например: <ol><li></li></ol>, <ul><li><ol><li></li></ol></li></ul> - два не вложенных списка (и один вложенный)

Результатом работы функции parse будет список четырех чисел, посчитанных по формулам выше. 
  
ЧАСТЬ 2
В этом задании продолжаем работать со страницами из wikipedia. Необходимо реализовать механизм сбора статистики по нескольким страницам. Сложность задачи состоит 
в том, что сначала нужно будет определить страницы, с которых необходимо собирать статистику. В качестве входных данных служат названия двух статей(страниц). 
Гарантируется, что файлы обеих статей есть в папке wiki и из первой статьи можно попасть в последнюю, переходя по ссылкам только на те статьи, копии которых есть 
в папке wiki.
  Например, на вход подаются страницы: Stone_Age и Python_(programming_language). В статье Stone_Age есть ссылка на Brain, в ней на Artificial_intelligence, а в 
ней на Python_(programming_language) и это кратчайший путь от Stone_Age до Python_(programming_language). Ваша задача — найти самый короткий путь (гарантируется, 
что существует только один путь минимальной длины), а затем с помощью функции parse из предыдущего задания собрать статистику по всем статьям в найденном пути. 
  Результат нужно вернуть в виде словаря, ключами которого являются имена статей, а значениями списки со статистикой.
